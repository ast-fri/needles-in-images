<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Finding Needles in Images</title>
  <style>
    body {
      margin: 0;
      font-family: 'Segoe UI', Tahoma, sans-serif;
      background-color: #fafafa;
      color: #222;
      line-height: 1.7;
    }

    .container {
      max-width: 960px;
      margin: 0 auto;
      padding: 40px 20px;
    }

    .header {
      text-align: center;
      margin-bottom: 40px;
    }

    .header h1 {
      font-size: 2.4rem;
      font-weight: 700;
      color: #000;
      margin-bottom: 12px;
      border-bottom: 2px solid #ccc;
      display: inline-block;
      padding-bottom: 6px;
    }


    .header p {
      font-size: 1rem;
      color: #555;
    }

    .links-section {
      display: flex;
      justify-content: center;
      gap: 15px;
      flex-wrap: wrap;
      margin-top: 25px;
    }

    .link-button {
      display: inline-flex;
      align-items: center;
      gap: 8px;
      background: #222;
      color: #fff;
      text-decoration: none;
      padding: 10px 20px;
      border-radius: 30px;
      font-size: 0.9rem;
      transition: background 0.2s ease;
    }

    .link-button:hover {
      background: #444;
    }

    .link-button.github {
      background: #24292e;
    }

    .link-button.huggingface {
      background: #ff9900;
    }

    .link-button.arxiv {
      background: #b91c1c;
    }

    .section {
      background: #fff;
      border: 1px solid #e0e0e0;
      border-radius: 8px;
      padding: 30px;
      margin-bottom: 40px;
      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.02);
    }

    .section-title {
      font-size: 1.5rem;
      font-weight: 500;
      margin-bottom: 20px;
      border-bottom: 1px solid #ddd;
      padding-bottom: 10px;
      color: #111;
    }

    .abstract {
      font-size: 1rem;
      color: #333;
      text-align: justify;
    }

    .image-row {
      display: flex;
      flex-wrap: wrap;
      gap: 20px;
      justify-content: center;
      align-items: center;
    }

    .image-row img {
      border-radius: 8px;
      box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
      max-width: 100%;
    }

    .image-label {
      text-align: center;
      color: #666;
      font-size: 0.9rem;
      margin-top: 8px;
    }

    .footer {
      text-align: center;
      font-size: 0.9rem;
      color: #888;
      margin-top: 60px;
      padding: 20px;
    }

    @media (max-width: 768px) {
      .image-row {
        flex-direction: column;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <header class="header">
      <h1>Finding Needles in Images: Can Multi-modal LLMs Locate Fine Details?</h1>
      <p>A professional benchmark for fine-grained visual document understanding</p>

      <div class="links-section">
        <a href="https://github.com/ParthT25/needles-in-images" class="link-button github">
          <span>ðŸ“„</span> GitHub
        </a>
        <a href="https://huggingface.co/datasets/ParthT25/needles-in-images" class="link-button huggingface">
          <span>ðŸ¤—</span> Hugging Face
        </a>
        <a href="https://arxiv.org/abs/your-paper-id" class="link-button arxiv">
          <span>ðŸ“š</span> arXiv
        </a>
      </div>
    </header>

    <section class="section">
      <div class="section-title">Abstract</div>
      <p class="abstract">
        While Multi-modal Large Language Models (MLLMs) have shown impressive capabilities in document understanding tasks, their ability to locate and reason about fine-grained details within complex documents remains understudied. Consider searching a restaurant menu for a specific nutritional detail or locating a particular warranty clause in a manual â€“ tasks that require precise attention to minute details within a larger context, akin to Finding Needles in Images (NiM). To address this gap, we introduce NiM-Benchmark, a carefully curated benchmark spanning diverse real-world documents including newspapers, menus, and lecture images, specifically designed to evaluate MLLMsâ€™ capability in these intricate tasks. Building on this, we further propose Spot-IT, a simple yet effective approach that enhances MLLMs capability through intelligent patch selection and Gaussian attention, motivated from how humans zoom and focus when searching documents. Our extensive experiments reveal both the capabilities and limitations of current MLLMs in handling fine-grained document understanding tasks, while demonstrating the effectiveness of our approach. Spot-IT achieves significant improvements over baseline methods, particularly in scenarios requiring precise detail extraction from complex layouts.
      </p>
    </section>

    <section class="section">
      <div class="section-title">Restaurant menu example</div>
      <div class="image-row">
        <div>
          <img src="Sample_imgs/Restaurant.png" alt="Full Image" class="responsive-image">
          <div class="image-label">NiM benchmark sample image with Spot-IT(Restaurant Menus)</div>
        </div>
      </div>
      </section>

      <section class="section">
      <div class="section-title">Lecture screenshot example</div>
      <div class="image-row">
        <div>
          <img src="Sample_imgs/Lecture SS.png" alt="Full Image" class="responsive-image">
          <div class="image-label">NiM benchmark sample image with Spot-IT</div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="section-title">Website Screenshot example</div>
      <div class="image-row">
        <div>
          <img src="Sample_imgs/Website_SS.png" alt="Full Image" class="responsive-image">
          <div class="image-label">NiM benchmark sample image with Spot-IT</div>
        </div>
      </div>
    </section>
    

    <div class="footer">
      Â© 2024 Research Project | Finding Needles in Images
    </div>
  </div>
</body>
</html>
