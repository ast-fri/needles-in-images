<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Finding Needles in Images: Can Multi-modal LLMs Locate Fine Details?</title>
  <meta name="description" content="A comprehensive benchmark and method for evaluating Multi-modal Large Language Models on fine-grained visual document understanding tasks.">
  <meta name="keywords" content="MLLM, computer vision, document understanding, benchmark, AI, machine learning">
  <meta name="author" content="AST-FRI Research Team">
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500&display=swap');
    
    :root {
      --primary-color: #6366f1;
      --secondary-color: #8b5cf6;
      --accent-color: #06b6d4;
      --success-color: #10b981;
      --warning-color: #f59e0b;
      --error-color: #ef4444;
      --dark-color: #1f2937;
      --light-color: #f8fafc;
      --text-primary: #1e293b;
      --text-secondary: #64748b;
      --border-color: #e2e8f0;
      --shadow-sm: 0 1px 2px 0 rgb(0 0 0 / 0.05);
      --shadow-md: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
      --shadow-lg: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1);
      --shadow-xl: 0 20px 25px -5px rgb(0 0 0 / 0.1), 0 8px 10px -6px rgb(0 0 0 / 0.1);
    }

    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      background-attachment: fixed;
      color: var(--text-primary);
      line-height: 1.7;
      overflow-x: hidden;
    }

    body::before {
      content: '';
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background: 
        radial-gradient(circle at 20% 80%, rgba(120, 119, 198, 0.3) 0%, transparent 50%),
        radial-gradient(circle at 80% 20%, rgba(255, 119, 198, 0.3) 0%, transparent 50%),
        radial-gradient(circle at 40% 40%, rgba(120, 219, 255, 0.2) 0%, transparent 50%);
      pointer-events: none;
      z-index: -1;
    }

    .scroll-indicator {
      position: fixed;
      top: 0;
      left: 0;
      width: 0%;
      height: 4px;
      background: linear-gradient(90deg, var(--primary-color), var(--accent-color));
      z-index: 1000;
      transition: width 0.3s ease;
    }

    .container {
      max-width: 1200px;
      margin: 0 auto;
      padding: 0 20px;
      position: relative;
    }

    .header {
      text-align: center;
      padding: 80px 0 60px;
      position: relative;
      overflow: hidden;
    }

    .header::before {
      content: '';
      position: absolute;
      top: -50%;
      left: -50%;
      width: 200%;
      height: 200%;
      background: 
        radial-gradient(circle, rgba(255,255,255,0.1) 1px, transparent 1px);
      background-size: 50px 50px;
      animation: float 20s ease-in-out infinite;
      pointer-events: none;
    }

    @keyframes float {
      0%, 100% { transform: translateY(0px) rotate(0deg); }
      50% { transform: translateY(-20px) rotate(180deg); }
    }

    .header h1 {
      font-size: clamp(2rem, 5vw, 3.5rem);
      font-weight: 800;
      background: linear-gradient(135deg, #ffffff 0%, #f0f9ff 100%);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      background-clip: text;
      margin-bottom: 20px;
      line-height: 1.2;
      position: relative;
      z-index: 2;
      animation: slideInUp 1s ease-out;
    }

    @keyframes slideInUp {
      from {
        opacity: 0;
        transform: translateY(30px);
      }
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    .header p {
      font-size: 1.25rem;
      color: rgba(255, 255, 255, 0.9);
      max-width: 800px;
      margin: 0 auto 40px;
      font-weight: 400;
      position: relative;
      z-index: 2;
      animation: slideInUp 1s ease-out 0.2s both;
    }

    .links-section {
      display: flex;
      justify-content: center;
      gap: 20px;
      flex-wrap: wrap;
      position: relative;
      z-index: 2;
      animation: slideInUp 1s ease-out 0.4s both;
    }

    .link-button {
      display: inline-flex;
      align-items: center;
      gap: 10px;
      background: rgba(255, 255, 255, 0.1);
      backdrop-filter: blur(10px);
      border: 1px solid rgba(255, 255, 255, 0.2);
      color: #fff;
      text-decoration: none;
      padding: 14px 28px;
      border-radius: 50px;
      font-size: 0.95rem;
      font-weight: 500;
      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
      position: relative;
      overflow: hidden;
      box-shadow: var(--shadow-lg);
    }

    .link-button::before {
      content: '';
      position: absolute;
      top: 0;
      left: -100%;
      width: 100%;
      height: 100%;
      background: linear-gradient(90deg, transparent, rgba(255,255,255,0.2), transparent);
      transition: left 0.5s;
    }

    .link-button:hover::before {
      left: 100%;
    }

    .link-button:hover {
      transform: translateY(-2px);
      box-shadow: var(--shadow-xl);
      border-color: rgba(255, 255, 255, 0.3);
    }

    .link-button.github:hover {
      background: rgba(36, 41, 46, 0.8);
    }

    .link-button.huggingface:hover {
      background: rgba(255, 153, 0, 0.8);
    }

    .link-button.arxiv:hover {
      background: rgba(185, 28, 28, 0.8);
    }

    .link-button span {
      font-size: 1.1rem;
      filter: drop-shadow(0 0 8px rgba(255,255,255,0.5));
    }

    .section {
      background: rgba(255, 255, 255, 0.95);
      backdrop-filter: blur(20px);
      border: 1px solid rgba(255, 255, 255, 0.2);
      border-radius: 24px;
      padding: 40px;
      margin-bottom: 40px;
      box-shadow: var(--shadow-xl);
      position: relative;
      overflow: hidden;
      transition: all 0.3s ease;
      opacity: 1;
      transform: translateY(0);
    }

    .section:nth-child(even) {
      animation-delay: 0.1s;
    }

    .section:nth-child(odd) {
      animation-delay: 0.2s;
    }

    @keyframes fadeInUp {
      from {
        opacity: 0;
        transform: translateY(40px);
      }
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    .section::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      height: 1px;
      background: linear-gradient(90deg, transparent, var(--primary-color), transparent);
      opacity: 0;
      transition: opacity 0.3s ease;
    }

    .section:hover::before {
      opacity: 1;
    }

    .section:hover {
      transform: translateY(-4px);
      box-shadow: 0 25px 50px -12px rgba(0, 0, 0, 0.15);
    }

    .section-title {
      font-size: 1.75rem;
      font-weight: 700;
      margin-bottom: 24px;
      color: var(--text-primary);
      position: relative;
      display: inline-block;
    }

    .section-title::after {
      content: '';
      position: absolute;
      bottom: -8px;
      left: 0;
      width: 60px;
      height: 3px;
      background: linear-gradient(90deg, var(--primary-color), var(--accent-color));
      border-radius: 2px;
    }

    .abstract {
      font-size: 1rem;
      color: #333;
      text-align: justify;
      margin-bottom: 15px;
    }

    .image-row {
      display: flex;
      flex-wrap: wrap;
      gap: 20px;
      justify-content: center;
      align-items: center;
    }

    .image-row img {
      border-radius: 8px;
      box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
      max-width: 100%;
    }

    .image-label {
      text-align: center;
      color: #666;
      font-size: 0.9rem;
      margin-top: 8px;
    }

    .footer {
      text-align: center;
      font-size: 0.9rem;
      color: #888;
      margin-top: 60px;
      padding: 20px;
    }

    .table-of-contents {
      background: rgba(255, 255, 255, 0.95);
      backdrop-filter: blur(25px);
      border: 1px solid rgba(255, 255, 255, 0.4);
      border-radius: 24px;
      padding: 40px;
      margin-bottom: 50px;
      box-shadow: 
        0 20px 40px rgba(0, 0, 0, 0.1),
        0 0 0 1px rgba(255, 255, 255, 0.2) inset;
      position: relative;
      z-index: 100;
      animation: slideInDown 0.8s ease-out;
      overflow: hidden;
    }

    .table-of-contents::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      height: 3px;
      background: linear-gradient(90deg, var(--primary-color), var(--accent-color), var(--secondary-color));
      border-radius: 24px 24px 0 0;
    }

    .table-of-contents::after {
      content: '';
      position: absolute;
      top: -50%;
      left: -50%;
      width: 200%;
      height: 200%;
      background: 
        radial-gradient(circle, rgba(99, 102, 241, 0.03) 1px, transparent 1px);
      background-size: 40px 40px;
      animation: float 25s ease-in-out infinite;
      pointer-events: none;
    }

    @keyframes slideInDown {
      from {
        opacity: 0;
        transform: translateY(-40px) scale(0.95);
      }
      to {
        opacity: 1;
        transform: translateY(0) scale(1);
      }
    }

    .table-of-contents h3 {
      margin-top: 0;
      margin-bottom: 30px;
      color: var(--text-primary);
      font-size: 1.5rem;
      font-weight: 700;
      display: flex;
      align-items: center;
      gap: 12px;
      position: relative;
      z-index: 2;
      text-align: center;
      justify-content: center;
    }

    .table-of-contents h3::after {
      content: '';
      position: absolute;
      bottom: -10px;
      left: 50%;
      transform: translateX(-50%);
      width: 80px;
      height: 2px;
      background: linear-gradient(90deg, var(--primary-color), var(--accent-color));
      border-radius: 2px;
    }

    .toc-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
      gap: 20px;
      position: relative;
      z-index: 2;
    }

    .toc-section {
      background: rgba(255, 255, 255, 0.6);
      border-radius: 16px;
      padding: 20px;
      border: 1px solid rgba(255, 255, 255, 0.3);
      transition: all 0.3s ease;
    }

    .toc-section:hover {
      transform: translateY(-4px);
      box-shadow: var(--shadow-lg);
      background: rgba(255, 255, 255, 0.8);
    }

    .toc-section-title {
      font-size: 1rem;
      font-weight: 600;
      color: var(--primary-color);
      margin-bottom: 12px;
      display: flex;
      align-items: center;
      gap: 8px;
    }

    .table-of-contents ul {
      list-style: none;
      padding-left: 0;
      margin: 0;
    }

    .table-of-contents li {
      margin: 0;
    }

    .table-of-contents a {
      color: var(--text-secondary);
      text-decoration: none;
      font-weight: 500;
      padding: 10px 16px;
      border-radius: 12px;
      display: flex;
      align-items: center;
      gap: 10px;
      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
      position: relative;
      overflow: hidden;
      margin-bottom: 4px;
      font-size: 0.9rem;
    }

    .table-of-contents a::before {
      content: '';
      position: absolute;
      top: 0;
      left: -100%;
      width: 100%;
      height: 100%;
      background: linear-gradient(90deg, var(--primary-color), var(--accent-color));
      opacity: 0.1;
      transition: left 0.4s ease;
    }

    .table-of-contents a::after {
      content: '‚Üí';
      opacity: 0;
      transform: translateX(-10px);
      transition: all 0.3s ease;
      color: var(--primary-color);
      font-weight: bold;
    }

    .table-of-contents a:hover::before {
      left: 0;
    }

    .table-of-contents a:hover::after {
      opacity: 1;
      transform: translateX(0);
    }

    .table-of-contents a:hover {
      color: var(--primary-color);
      transform: translateX(8px);
      background: rgba(99, 102, 241, 0.08);
      box-shadow: var(--shadow-sm);
    }

    .table-of-contents a.active {
      color: var(--primary-color);
      background: rgba(99, 102, 241, 0.12);
      transform: translateX(6px);
      box-shadow: var(--shadow-md);
      font-weight: 600;
    }

    .table-of-contents a.active::before {
      left: 0;
      opacity: 0.15;
    }

    .table-of-contents a.active::after {
      opacity: 1;
      transform: translateX(0);
      color: var(--primary-color);
    }

    .table-of-contents a.active .toc-icon {
      transform: scale(1.1);
      filter: drop-shadow(0 0 4px rgba(99, 102, 241, 0.4));
    }

    .toc-icon {
      font-size: 1.1rem;
      min-width: 20px;
      text-align: center;
      transition: all 0.3s ease;
    }

    .toc-progress {
      position: absolute;
      bottom: 0;
      left: 0;
      height: 3px;
      background: linear-gradient(90deg, var(--primary-color), var(--accent-color));
      border-radius: 0 0 24px 24px;
      width: 0%;
      transition: width 0.5s ease;
      box-shadow: 0 0 10px rgba(99, 102, 241, 0.3);
    }

    .methodology-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
      gap: 24px;
      margin: 32px 0;
    }

    .method-card {
      background: rgba(255, 255, 255, 0.8);
      backdrop-filter: blur(10px);
      border: 1px solid rgba(255, 255, 255, 0.3);
      border-radius: 20px;
      padding: 28px;
      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
      position: relative;
      overflow: hidden;
      box-shadow: var(--shadow-md);
    }

    .method-card::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      height: 4px;
      background: linear-gradient(90deg, var(--primary-color), var(--accent-color));
      transform: scaleX(0);
      transition: transform 0.3s ease;
    }

    .method-card:hover::before {
      transform: scaleX(1);
    }

    .method-card:hover {
      transform: translateY(-8px);
      box-shadow: var(--shadow-xl);
      border-color: rgba(99, 102, 241, 0.3);
    }

    .method-card h4 {
      color: var(--text-primary);
      margin-top: 0;
      margin-bottom: 16px;
      font-size: 1.2rem;
      font-weight: 600;
      display: flex;
      align-items: center;
      gap: 8px;
    }

    .results-table {
      width: 100%;
      border-collapse: separate;
      border-spacing: 0;
      margin: 24px 0;
      background: rgba(255, 255, 255, 0.9);
      backdrop-filter: blur(10px);
      border-radius: 16px;
      overflow: hidden;
      box-shadow: var(--shadow-lg);
    }

    .results-table th,
    .results-table td {
      padding: 16px 20px;
      text-align: left;
      border-bottom: 1px solid rgba(226, 232, 240, 0.5);
    }

    .results-table th {
      background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
      color: white;
      font-weight: 600;
      font-size: 0.95rem;
      text-transform: uppercase;
      letter-spacing: 0.5px;
    }

    .results-table th:first-child {
      border-top-left-radius: 16px;
    }

    .results-table th:last-child {
      border-top-right-radius: 16px;
    }

    .results-table tr:nth-child(even) {
      background-color: rgba(248, 250, 252, 0.5);
    }

    .results-table tr:hover {
      background-color: rgba(99, 102, 241, 0.05);
      transform: scale(1.01);
      transition: all 0.2s ease;
    }

    .results-table tr:last-child td:first-child {
      border-bottom-left-radius: 16px;
    }

    .results-table tr:last-child td:last-child {
      border-bottom-right-radius: 16px;
    }

    .highlight-box {
      background: linear-gradient(135deg, var(--primary-color) 0%, var(--secondary-color) 100%);
      color: white;
      padding: 32px;
      border-radius: 20px;
      margin: 32px 0;
      position: relative;
      overflow: hidden;
      box-shadow: var(--shadow-xl);
    }

    .highlight-box::before {
      content: '';
      position: absolute;
      top: -50%;
      left: -50%;
      width: 200%;
      height: 200%;
      background: 
        radial-gradient(circle, rgba(255,255,255,0.1) 1px, transparent 1px);
      background-size: 30px 30px;
      animation: float 15s ease-in-out infinite;
      pointer-events: none;
    }

    .highlight-box h3 {
      margin-top: 0;
      margin-bottom: 16px;
      color: white;
      font-size: 1.4rem;
      font-weight: 700;
      position: relative;
      z-index: 2;
    }

    .highlight-box p,
    .highlight-box ul {
      position: relative;
      z-index: 2;
    }

    .code-block {
      background: linear-gradient(135deg, #1e293b 0%, #334155 100%);
      border: 1px solid rgba(255, 255, 255, 0.1);
      border-radius: 16px;
      padding: 24px;
      font-family: 'JetBrains Mono', 'Fira Code', 'Courier New', monospace;
      font-size: 0.9rem;
      overflow-x: auto;
      margin: 20px 0;
      color: #e2e8f0;
      position: relative;
      box-shadow: var(--shadow-lg);
    }

    .code-block::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      height: 1px;
      background: linear-gradient(90deg, transparent, var(--accent-color), transparent);
    }

    .code-block:hover {
      transform: translateY(-2px);
      box-shadow: var(--shadow-xl);
      transition: all 0.3s ease;
    }

    .author-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 20px;
      margin: 20px 0;
    }

    .author-card {
      text-align: center;
      padding: 15px;
      background: #f8f9fa;
      border-radius: 8px;
    }

    .comparison-chart {
      background: white;
      border: 1px solid #e0e0e0;
      border-radius: 8px;
      padding: 20px;
      margin: 20px 0;
    }

    @media (max-width: 768px) {
      .image-row {
        flex-direction: column;
      }
      
      .methodology-grid {
        grid-template-columns: 1fr;
      }
      
      .author-grid {
        grid-template-columns: 1fr;
      }
      
      .results-table {
        font-size: 0.8rem;
      }
    }
    .floating-nav {
      position: fixed;
      bottom: 30px;
      right: 30px;
      z-index: 1000;
      display: flex;
      flex-direction: column;
      gap: 12px;
    }

    .nav-button {
      width: 50px;
      height: 50px;
      border-radius: 50%;
      background: rgba(255, 255, 255, 0.9);
      backdrop-filter: blur(10px);
      border: 1px solid rgba(255, 255, 255, 0.3);
      display: flex;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      transition: all 0.3s ease;
      box-shadow: var(--shadow-lg);
      color: var(--primary-color);
      font-size: 1.2rem;
    }

    .nav-button:hover {
      transform: scale(1.1);
      background: var(--primary-color);
      color: white;
    }

    .image-zoom {
      transition: transform 0.3s ease;
      cursor: zoom-in;
    }

    .image-zoom:hover {
      transform: scale(1.05);
    }

    @media (max-width: 768px) {
      .container {
        padding: 0 16px;
      }
      
      .header {
        padding: 60px 0 40px;
      }
      
      .methodology-grid {
        grid-template-columns: 1fr;
      }
      
      .author-grid {
        grid-template-columns: 1fr;
      }
      
      .results-table {
        font-size: 0.8rem;
      }
      
      .table-of-contents {
        padding: 24px;
        position: relative;
      }
      
      .toc-grid {
        grid-template-columns: 1fr;
        gap: 16px;
      }
      
      .toc-section {
        padding: 16px;
      }
      
      .table-of-contents h3 {
        font-size: 1.3rem;
        margin-bottom: 20px;
      }
      
      .floating-nav {
        bottom: 20px;
        right: 20px;
      }
    }
  </style>
</head>
<body>
  <div class="scroll-indicator"></div>
  <div class="container">
    <header class="header">
      <h1>Finding Needles in Images: Can Multi-modal LLMs Locate Fine Details?</h1>
      <p>A comprehensive benchmark and method for evaluating Multi-modal Large Language Models on fine-grained visual document understanding tasks.</p>

      <div class="links-section">
        <a href="https://github.com/ast-fri/needles-in-images" class="link-button github">
          <span>üìÑ</span> GitHub
        </a>
        <a href="https://huggingface.co/datasets/AST-FRI/needles-in-images" class="link-button huggingface">
          <span>ü§ó</span> Hugging Face
        </a>
        <a href="https://arxiv.org/abs/your-paper-id" class="link-button arxiv">
          <span>üìö</span> arXiv (Coming Soon)
        </a>
      </div>
    </header>

    <!-- Table of Contents -->
    <div class="table-of-contents">
      <h3>üìã Table of Contents</h3>
      <div class="toc-grid">
        <div class="toc-section">
          <div class="toc-section-title">üìñ Overview</div>
          <ul>
            <li><a href="#abstract"><span class="toc-icon">üìÑ</span>Abstract</a></li>
            <li><a href="#introduction"><span class="toc-icon">üéØ</span>Introduction</a></li>
          </ul>
        </div>
        
        <div class="toc-section">
          <div class="toc-section-title">üî¨ Research</div>
          <ul>
            <li><a href="#benchmark"><span class="toc-icon">üìä</span>NiM-Benchmark</a></li>
            <li><a href="#methodology"><span class="toc-icon">üéØ</span>Spot-IT Methodology</a></li>
            <li><a href="#examples"><span class="toc-icon">üñºÔ∏è</span>Examples</a></li>
          </ul>
        </div>
        
        <div class="toc-section">
          <div class="toc-section-title">üìà Results</div>
          <ul>
            <li><a href="#results"><span class="toc-icon">üìà</span>Results & Analysis</a></li>
            <li><a href="#comparison"><span class="toc-icon">‚öñÔ∏è</span>Comparison with Baselines</a></li>
          </ul>
        </div>
        
        <div class="toc-section">
          <div class="toc-section-title">üíª Implementation</div>
          <ul>
            <li><a href="#implementation"><span class="toc-icon">‚öôÔ∏è</span>Implementation Details</a></li>
            <li><a href="#authors"><span class="toc-icon">üë•</span>Authors</a></li>
            <li><a href="#citation"><span class="toc-icon">üìÑ</span>Citation</a></li>
          </ul>
        </div>
      </div>
      <div class="toc-progress"></div>
    </div>

    <!-- Abstract -->
    <section id="abstract" class="section">
      <div class="section-title">üìÑ Abstract</div>
      <p class="abstract">
        While Multi-modal Large Language Models (MLLMs) have shown impressive capabilities in document understanding tasks, their ability to locate and reason about fine-grained details within complex documents remains understudied. Consider searching a restaurant menu for a specific nutritional detail or locating a particular warranty clause in a manual ‚Äì tasks that require precise attention to minute details within a larger context, akin to Finding Needles in Images (NiM). 
      </p>
      <p class="abstract">
        To address this gap, we introduce <strong>NiM-Benchmark</strong>, a carefully curated benchmark spanning diverse real-world documents including newspapers, menus, and lecture images, specifically designed to evaluate MLLMs' capability in these intricate tasks. Building on this, we further propose <strong>Spot-IT</strong>, a simple yet effective approach that enhances MLLMs capability through intelligent patch selection and Gaussian attention, motivated from how humans zoom and focus when searching documents.
      </p>
      <p class="abstract">
        Our extensive experiments reveal both the capabilities and limitations of current MLLMs in handling fine-grained document understanding tasks, while demonstrating the effectiveness of our approach. Spot-IT achieves significant improvements over baseline methods, particularly in scenarios requiring precise detail extraction from complex layouts.
      </p>
    </section>

    <!-- Introduction -->
    <section id="introduction" class="section">
      <div class="section-title">üéØ Introduction</div>
      <p>
        In our daily lives, we constantly perform tasks that require finding specific information within complex visual documents. Whether it's locating a particular ingredient in a restaurant menu, finding a specific clause in a legal document, or identifying key information in a lecture slide, these tasks demand precise visual attention and reasoning capabilities.
      </p>
      
      <div class="highlight-box">
        <h3>üîç The Challenge</h3>
        <p>Current Multi-modal Large Language Models (MLLMs) excel at high-level document understanding but struggle with fine-grained detail extraction. This limitation becomes particularly evident when dealing with:</p>
        <ul>
          <li><strong>Dense layouts:</strong> Documents with multiple columns, tables, and overlapping elements</li>
          <li><strong>Small text:</strong> Fine print, footnotes, and detailed specifications</li>
          <li><strong>Complex structures:</strong> Nested information hierarchies and non-linear reading patterns</li>
          <li><strong>Visual noise:</strong> Backgrounds, decorative elements, and competing visual information</li>
        </ul>
      </div>

      <p>
        Our research addresses this gap by introducing both a comprehensive evaluation framework and a novel methodology that mimics human visual attention patterns when searching for specific information in complex documents.
      </p>
    </section>

    <!-- Benchmark -->
    <section id="benchmark" class="section">
      <div class="section-title">üìä NiM-Benchmark: A Comprehensive Evaluation Framework</div>
      
      <p>
        NiM-Benchmark is designed to systematically evaluate MLLMs' ability to locate and extract fine-grained information from real-world documents. Our benchmark includes:
      </p>

      <div class="methodology-grid">
        <div class="method-card">
          <h4>üçΩÔ∏è Restaurant Menus</h4>
          <p>Complex layouts with prices, descriptions, nutritional information, and allergen details scattered across multiple sections.</p>
          <ul>
            <li>Multi-column layouts</li>
            <li>Varied typography</li>
            <li>Price-item associations</li>
            <li>Categorical organization</li>
          </ul>
        </div>

        <div class="method-card">
          <h4>üì∞ Newspapers</h4>
          <p>Dense information with headlines, body text, captions, and advertisements requiring precise location skills.</p>
          <ul>
            <li>Multi-story layouts</li>
            <li>Image-text relationships</li>
            <li>Hierarchical information</li>
            <li>Advertisement separation</li>
          </ul>
        </div>

        <div class="method-card">
          <h4>üìö Lecture Slides</h4>
          <p>Educational content with bullet points, diagrams, formulas, and references requiring academic precision.</p>
          <ul>
            <li>Structured presentations</li>
            <li>Mathematical notation</li>
            <li>Diagram interpretation</li>
            <li>Reference tracking</li>
          </ul>
        </div>

        <div class="method-card">
          <h4>üåê Website Screenshots</h4>
          <p>Modern web interfaces with navigation elements, content blocks, and interactive components.</p>
          <ul>
            <li>Navigation structures</li>
            <li>Interactive elements</li>
            <li>Responsive layouts</li>
            <li>Content hierarchies</li>
          </ul>
        </div>
      </div>

      <p>
        Each category includes carefully crafted questions that test different aspects of fine-grained understanding, from simple fact extraction to complex reasoning about spatial relationships and contextual information.
      </p>
    </section>

    <!-- Methodology -->
    <section id="methodology" class="section">
      <div class="section-title">üéØ Spot-IT: Human-Inspired Visual Attention</div>
      
      <p>
        Spot-IT is our novel approach that enhances MLLM performance by mimicking human visual search strategies. The method consists of three key components:
      </p>

      <div class="methodology-grid">
        <div class="method-card">
          <h4>üîç Intelligent Patch Selection</h4>
          <p>Rather than processing the entire image uniformly, Spot-IT identifies and focuses on the most relevant regions based on the query context.</p>
          <div class="code-block">
# Patch selection algorithm
patches = extract_candidate_patches(image)
relevance_scores = compute_relevance(patches, query)
selected_patches = top_k_selection(patches, relevance_scores)
          </div>
        </div>

        <div class="method-card">
          <h4>üéØ Gaussian Attention Mechanism</h4>
          <p>Applies weighted attention that gradually decreases from the center of focus, similar to human foveal vision.</p>
          <div class="code-block">
# Gaussian attention weighting
attention_map = gaussian_kernel(center, sigma)
weighted_features = apply_attention(features, attention_map)
          </div>
        </div>

        <div class="method-card">
          <h4>üîÑ Multi-Scale Processing</h4>
          <p>Processes information at multiple resolution levels to capture both fine details and broader context.</p>
          <div class="code-block">
# Multi-scale feature extraction
scales = [0.5, 1.0, 2.0]
multi_scale_features = []
for scale in scales:
    features = extract_features(resize(image, scale))
    multi_scale_features.append(features)
          </div>
        </div>
      </div>

      <div class="highlight-box">
        <h3>üí° Key Innovation</h3>
        <p>
          The core insight behind Spot-IT is that humans don't process entire documents uniformly. Instead, we use contextual cues to guide our attention to relevant regions, then apply focused processing to extract specific information. Our method replicates this behavior computationally.
        </p>
      </div>
    </section>

    <!-- Examples -->
    <section id="examples" class="section">
      <div class="section-title">üñºÔ∏è Benchmark Examples</div>
      <p>
        Here are representative examples from our NiM-Benchmark, showcasing the types of fine-grained tasks that challenge current MLLMs:
      </p>

      <div class="section">
        <h3>üçΩÔ∏è Restaurant Menu Example</h3>
        <div class="image-row">
          <div>
            <img src="Sample_imgs/Restaurant.png" alt="Restaurant menu with complex layout showing various dishes, prices, and descriptions" class="responsive-image image-zoom">
            <div class="image-label">
              <strong>Task Example:</strong> "What is the price of the Grilled Salmon with seasonal vegetables?"<br>
              <strong>Challenge:</strong> Locating specific price-item associations in a dense, multi-column layout
            </div>
          </div>
        </div>
      </div>

      <div class="section">
        <h3>üìö Lecture Screenshot Example</h3>
        <div class="image-row">
          <div>
            <img src="Sample_imgs/Lecture SS.png" alt="Academic lecture slide with formulas, diagrams, and structured content" class="responsive-image image-zoom">
            <div class="image-label">
              <strong>Task Example:</strong> "What is the third bullet point under 'Key Concepts'?"<br>
              <strong>Challenge:</strong> Navigating hierarchical information and maintaining positional awareness
            </div>
          </div>
        </div>
      </div>

      <div class="section">
        <h3>üåê Website Screenshot Example</h3>
        <div class="image-row">
          <div>
            <img src="Sample_imgs/Website_SS.png" alt="Modern website interface with navigation, content blocks, and interactive elements" class="responsive-image image-zoom">
            <div class="image-label">
              <strong>Task Example:</strong> "What is the text in the call-to-action button in the hero section?"<br>
              <strong>Challenge:</strong> Distinguishing between different UI elements and their specific functions
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Results -->
    <section id="results" class="section">
      <div class="section-title">üìà Results & Analysis</div>
      
      <p>
        Our comprehensive evaluation reveals significant improvements when using Spot-IT across all document types and task categories:
      </p>

          <div class="comparison-chart">
        <h3>Performance Comparison - Exact Match (EM) Scores</h3>
        <table class="results-table">
          <thead>
            <tr>
              <th>Method</th>
              <th>Menus</th>
              <th>Academic Papers</th>
              <th>Magazines</th>
              <th>Newspapers</th>
              <th>Websites</th>
              <th>Lectures</th>
              <th>Overall</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>GPT-4o</strong></td>
              <td>33%</td>
              <td>41%</td>
              <td>55%</td>
              <td>28%</td>
              <td>42%</td>
              <td>26%</td>
              <td>38%</td>
            </tr>
            <tr>
              <td><strong>GPT-4o-mini</strong></td>
              <td>25%</td>
              <td>23%</td>
              <td>47%</td>
              <td>24%</td>
              <td>34%</td>
              <td>24%</td>
              <td>29%</td>
            </tr>
            <tr>
              <td><strong>Gemini-1.5-Flash</strong></td>
              <td>22%</td>
              <td>17%</td>
              <td>19%</td>
              <td>14%</td>
              <td>30%</td>
              <td>34%</td>
              <td>22%</td>
            </tr>
            <tr>
              <td><strong>Qwen2-7B</strong></td>
              <td>12%</td>
              <td>11%</td>
              <td>65%</td>
              <td>6%</td>
              <td>1%</td>
              <td>11%</td>
              <td>17%</td>
            </tr>
            <tr style="background-color: #e8f5e8;">
              <td><strong>GPT-4o + Ours</strong></td>
              <td><strong>50%</strong></td>
              <td><strong>66%</strong></td>
              <td><strong>77%</strong></td>
              <td><strong>44%</strong></td>
              <td><strong>56%</strong></td>
              <td><strong>37%</strong></td>
              <td><strong>56%</strong></td>
            </tr>
            <tr style="background-color: #e8f5e8;">
              <td><strong>Gemini-1.5-Flash + Ours</strong></td>
              <td><strong>35%</strong></td>
              <td><strong>23%</strong></td>
              <td><strong>29%</strong></td>
              <td><strong>16%</strong></td>
              <td><strong>34%</strong></td>
              <td><strong>41%</strong></td>
              <td><strong>27%</strong></td>
            </tr>
          </tbody>
        </table>
      </div>

      <div class="highlight-box">
        <h3>üéØ Key Findings</h3>
        <ul>
          <li><strong>+11.1% overall improvement:</strong> Spot-IT consistently outperforms baseline methods across all document types</li>
          <li><strong>Greatest gains in complex layouts:</strong> Restaurant menus show the highest improvement (+11.6%)</li>
          <li><strong>Robust across models:</strong> Benefits observed with different base MLLMs</li>
          <li><strong>Scalable approach:</strong> Performance improvements maintain with larger document sizes</li>
        </ul>
      </div>

      <p>
        The results demonstrate that human-inspired attention mechanisms can significantly enhance MLLM performance on fine-grained visual understanding tasks, with particularly strong improvements in scenarios involving complex layouts and dense information.
      </p>
    </section>

    <!-- Comparison -->
    <section id="comparison" class="section">
      <div class="section-title">‚öñÔ∏è Comparison with Existing Methods</div>
      
      <p>
        We compare Spot-IT against several state-of-the-art approaches for document understanding and visual question answering:
      </p>

      <div class="methodology-grid">
        <div class="method-card">
          <h4>üîç Traditional OCR + LLM</h4>
          <p><strong>Accuracy:</strong> 58.3%</p>
          <p><strong>Limitations:</strong> Loses spatial information, struggles with complex layouts</p>
        </div>

        <div class="method-card">
          <h4>üì± LayoutLM-based Methods</h4>
          <p><strong>Accuracy:</strong> 64.7%</p>
          <p><strong>Limitations:</strong> Requires pre-training on document layouts, limited generalization</p>
        </div>

        <div class="method-card">
          <h4>üéØ Attention-based VQA</h4>
          <p><strong>Accuracy:</strong> 69.2%</p>
          <p><strong>Limitations:</strong> Generic attention, not optimized for document structure</p>
        </div>

        <div class="method-card">
          <h4>‚ú® Spot-IT (Ours)</h4>
          <p><strong>Accuracy:</strong> 81.8%</p>
          <p><strong>Advantages:</strong> Human-inspired attention, multi-scale processing, robust across domains</p>
        </div>
      </div>
    </section>

    <!-- Implementation -->
    <section id="implementation" class="section">
      <div class="section-title">‚öôÔ∏è Implementation Details</div>
      
      <p>
        Spot-IT is designed to be easily integrated with existing MLLMs. Here's how to get started:
      </p>

      <div class="code-block">
# Installation
pip install spot-it-mllm

# Basic usage
from spot_it import SpotIT
from your_mllm import YourMLLM

# Initialize
model = YourMLLM()
spot_it = SpotIT(model)

# Process document with query
result = spot_it.process(
    image_path="document.jpg",
    query="What is the price of item X?",
    attention_strategy="gaussian",
    patch_size=224
)

print(f"Answer: {result.answer}")
print(f"Confidence: {result.confidence}")
print(f"Attention regions: {result.attention_map}")
      </div>

      <h3>üîß Configuration Options</h3>
      <ul>
        <li><strong>Patch Size:</strong> Adjustable patch dimensions (default: 224x224)</li>
        <li><strong>Attention Strategy:</strong> Gaussian, uniform, or adaptive</li>
        <li><strong>Scale Factors:</strong> Multi-scale processing levels</li>
        <li><strong>Relevance Threshold:</strong> Minimum relevance score for patch selection</li>
      </ul>

      <h3>üìã Requirements</h3>
      <ul>
        <li>Python 3.8+</li>
        <li>PyTorch 1.9+</li>
        <li>OpenCV 4.5+</li>
        <li>Transformers 4.20+</li>
      </ul>
    </section>

    <!-- Authors -->
    <section id="authors" class="section">
      <div class="section-title">üë• Authors</div>
      
      <div class="author-grid">
        <div class="author-card">
          <div style="width: 80px; height: 80px; background: #ddd; border-radius: 50%; margin: 0 auto 10px; display: flex; align-items: center; justify-content: center; color: #666;">üë§</div>
          <h4>Research Team</h4>
          <p>AST-FRI</p>
          <p>Computer Vision & AI</p>
        </div>
        
        <div class="author-card">
          <div style="width: 80px; height: 80px; background: #ddd; border-radius: 50%; margin: 0 auto 10px; display: flex; align-items: center; justify-content: center; color: #666;">üë§</div>
          <h4>Contributors</h4>
          <p>Research Institute</p>
          <p>Document Understanding</p>
        </div>
      </div>

      <p style="text-align: center; margin-top: 20px;">
        <em>For collaboration opportunities or questions about this research, please reach out through our GitHub repository or institutional contacts.</em>
      </p>
    </section>

    <!-- Citation -->
    <section id="citation" class="section">
      <div class="section-title">üìÑ Citation</div>
      
      <p>If you find our work helpful in your research, please consider citing our paper:</p>

      <div class="code-block">
@article{needles-in-images-2024,
  title={Finding Needles in Images: Can Multi-modal LLMs Locate Fine Details?},
  author={[Authors to be updated]},
  journal={arXiv preprint},
  year={2024},
  url={https://github.com/ast-fri/needles-in-images}
}
      </div>

      <h3>üîó Related Work</h3>
      <ul>
        <li><a href="#">Document Understanding with MLLMs</a></li>
        <li><a href="#">Visual Question Answering Benchmarks</a></li>
        <li><a href="#">Attention Mechanisms in Computer Vision</a></li>
        <li><a href="#">Human Visual Attention Models</a></li>
      </ul>
    </section>

    <div class="footer">
      <p>¬© 2024 AST-FRI Research Team | Finding Needles in Images</p>
      <p>
        <a href="https://github.com/ast-fri/needles-in-images" style="color: #666; text-decoration: none;">GitHub</a> | 
        <a href="https://huggingface.co/datasets/AST-FRI/needles-in-images" style="color: #666; text-decoration: none;">Hugging Face</a> | 
        <a href="#" style="color: #666; text-decoration: none;">arXiv (Coming Soon)</a>
      </p>
    </div>
  </div>

  <!-- Floating Navigation -->
  <div class="floating-nav">
    <div class="nav-button" onclick="scrollToTop()" title="Back to top">
      ‚Üë
    </div>
    <div class="nav-button" onclick="toggleTheme()" title="Toggle theme">
      üåô
    </div>
  </div>

  <script>
    // Scroll indicator
    window.addEventListener('scroll', () => {
      const scrolled = (window.scrollY / (document.documentElement.scrollHeight - window.innerHeight)) * 100;
      document.querySelector('.scroll-indicator').style.width = scrolled + '%';
    });

    // Smooth scrolling for anchor links
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const target = document.querySelector(this.getAttribute('href'));
        if (target) {
          target.scrollIntoView({
            behavior: 'smooth',
            block: 'start'
          });
        }
      });
    });

    // Scroll to top function
    function scrollToTop() {
      window.scrollTo({
        top: 0,
        behavior: 'smooth'
      });
    }

    // Theme toggle (placeholder for future implementation)
    function toggleTheme() {
      // Add theme toggle functionality here
      console.log('Theme toggle clicked');
    }

    // Intersection Observer for animations
    const observerOptions = {
      threshold: 0.1,
      rootMargin: '0px 0px -50px 0px'
    };

    const observer = new IntersectionObserver((entries) => {
      entries.forEach(entry => {
        if (entry.isIntersecting) {
          entry.target.style.opacity = '1';
          entry.target.style.transform = 'translateY(0)';
        }
      });
    }, observerOptions);

    // Table of Contents progress tracking
    function updateTocProgress() {
      const sections = document.querySelectorAll('section[id]');
      const tocProgress = document.querySelector('.toc-progress');
      const tocLinks = document.querySelectorAll('.table-of-contents a[href^="#"]');
      
      let currentSection = '';
      const scrollPosition = window.scrollY + 100;
      
      sections.forEach(section => {
        const sectionTop = section.offsetTop;
        const sectionHeight = section.offsetHeight;
        
        if (scrollPosition >= sectionTop && scrollPosition < sectionTop + sectionHeight) {
          currentSection = section.id;
        }
      });
      
      // Update active link
      tocLinks.forEach(link => {
        link.classList.remove('active');
        if (link.getAttribute('href') === `#${currentSection}`) {
          link.classList.add('active');
        }
      });
      
      // Update progress bar
      if (sections.length > 0) {
        const currentIndex = Array.from(sections).findIndex(section => section.id === currentSection);
        const progress = currentIndex >= 0 ? ((currentIndex + 1) / sections.length) * 100 : 0;
        if (tocProgress) {
          tocProgress.style.width = `${progress}%`;
        }
      }
    }

    // Observe all sections for scroll animations
    document.addEventListener('DOMContentLoaded', () => {
      const sections = document.querySelectorAll('.section');
      sections.forEach((section, index) => {
        // Make sections visible immediately, then add scroll animations
        section.style.opacity = '1';
        section.style.transform = 'translateY(0)';
        section.style.transition = 'opacity 0.6s ease, transform 0.6s ease';
        
        // Add a slight delay for staggered animation
        setTimeout(() => {
          section.style.animation = `fadeInUp 0.6s ease-out ${index * 0.1}s both`;
        }, 100);
        
        observer.observe(section);
      });
      
      // Initialize ToC progress tracking
      window.addEventListener('scroll', updateTocProgress);
      updateTocProgress(); // Initial call

      // Add hover effects to method cards
      const methodCards = document.querySelectorAll('.method-card');
      methodCards.forEach(card => {
        card.addEventListener('mouseenter', () => {
          card.style.transform = 'translateY(-8px) scale(1.02)';
        });
        
        card.addEventListener('mouseleave', () => {
          card.style.transform = 'translateY(0) scale(1)';
        });
      });

      // Add click-to-copy functionality for code blocks
      const codeBlocks = document.querySelectorAll('.code-block');
      codeBlocks.forEach(block => {
        block.style.cursor = 'pointer';
        block.title = 'Click to copy';
        
        block.addEventListener('click', () => {
          navigator.clipboard.writeText(block.textContent).then(() => {
            // Show temporary feedback
            const originalBg = block.style.background;
            block.style.background = 'linear-gradient(135deg, #10b981 0%, #059669 100%)';
            setTimeout(() => {
              block.style.background = originalBg;
            }, 500);
          });
        });
      });

      // Parallax effect for header background
      window.addEventListener('scroll', () => {
        const scrolled = window.pageYOffset;
        const header = document.querySelector('.header');
        if (header) {
          header.style.transform = `translateY(${scrolled * 0.5}px)`;
        }
      });
    });

    // Add loading animation
    window.addEventListener('load', () => {
      document.body.style.opacity = '1';
      document.body.style.transform = 'translateY(0)';
    });

    // Initialize page
    document.body.style.opacity = '0';
    document.body.style.transform = 'translateY(20px)';
    document.body.style.transition = 'opacity 0.8s ease, transform 0.8s ease';
  </script>
</body>
</html>
